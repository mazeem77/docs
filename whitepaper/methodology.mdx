---
title: "Evaluation Methodology"
---

## 6. Evaluation Methodology
The Chipforge Platform evaluates hardware designs using a comprehensive, weighted scoring function. The scoring methodology is **dynamic**, with both the weight distribution for the primary metrics and a minimum functionality threshold defined by the Chip Design Team in a challenge-specific `weights.json` configuration file. This allows the platform to emphasize specific design qualities, such as performance or silicon efficiency, based on the requirements of the current challenge.

### 6.1 Score Normalization
All individual metric scores and the final **Overall Score** ($O_c$) are normalized to the **0–1 range**, where a score of 1 represents 100% of the ideal metric performance.

| Metric        | Score Abbreviation | Description                                                     |
|---------------|--------------------|-----------------------------------------------------------------|
| Functionality | $F_c$              | Correct execution of the instruction set.                       |
| Performance   | $P_c$              | Instructions executed per second (throughput).                  |
| Area          | $Area$             | Efficiency of silicon utilization (smaller is better).          |
| Power         | N/A (TBD)          | Power consumption in milliwatts.                                |

---

## Dynamic Scoring Formula
The individual weights ($W_{Func}$, $W_{Delay}$, $W_{Area}$) and the minimum Functionality Threshold ($Threshold_{Func}$) are loaded from the `weights.json` file.

- **Constraint:** The submission must achieve a minimum Functionality Score ($F_c$) greater than or equal to the dynamic $Threshold_{Func}$ to receive a non-zero overall score.

$$
\text{IF } F_c \ge Threshold_{Func} :
$$

$$
O_c = \frac{(W_{Func} \cdot F_c) + (W_{Area} \cdot Area) + (W_{Perf} \cdot P_c)}{Total\_W}
$$

$$
\text{IF } F_c < Threshold_{Func} :
$$

$$
O_c = 0
$$

*Note:* The power metric is not currently evaluated, as it will be integrated for future challenges, such as the Neural Processing Unit (NPU) development specifically for edge AI applications, where power is a critical concern.

---

## Detailed Metric Evaluation

### 1. Functionality Score (\(F_c\))

This metric measures the design's functional correctness.

- **Test Generation & Golden Reference:** The Chip Design Team creates comprehensive test suites and runs them on the official **RISC-V ISA Simulator (SPIKE)** to generate the "golden output."
- **Design-Under-Test (DUT) Execution:** The same test cases are executed on the miner's design using the EDA Server's **Verilator** tool for simulation.
- **Scoring:** The \(F_c\) score is determined by comparing the DUT’s results against SPIKE's golden outputs.

$$
F_c = \frac{N_{correct}}{N_{total}}
$$

Where  
\(N_{correct}\) is the number of instructions that matched the golden result, and  
\(N_{total}\) is the total number of executed instructions.  
\(F_c\) is a value between 0 and 1.

---

### 2. Performance Score (\(P_c\))

Performance is quantified as **Instructions Per Second (IPS)**, representing the processing throughput.

- **IPC & Max Clock Speed (\(F_{max}\))**: The processor's **Instructions Per Cycle (IPC)** is measured using performance tests. The processor's maximum clock speed, referred to as \(F_{max}\) (Max Frequency), is determined through timing analysis using **OpenLane**.
- **Performance (IPS):** The throughput is calculated as:

$$
IPS = IPC \times F_{max}
$$

- **Normalization:** This raw IPS value is then normalized against a defined benchmark IPS to yield the 0–1 \(P_c\) score (a higher IPS results in a score closer to 1).
